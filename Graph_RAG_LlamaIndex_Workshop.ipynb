{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read credentials\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the variables\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Run the command and capture its output\n",
    "completed_process = subprocess.run(source_command, shell=True, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "# Parse the output to extract environment variables\n",
    "env_output = completed_process.stdout\n",
    "env_lines = env_output.splitlines()\n",
    "env_variables = {}\n",
    "\n",
    "for line in env_lines:\n",
    "    key, value = line.split('=', 1)\n",
    "    if any([\n",
    "        \"OPENAI\" in key,\n",
    "        \"NEBULA\" in key,\n",
    "        \"GRAPH\" in key,\n",
    "    ]):\n",
    "        env_variables[key] = value\n",
    "\n",
    "os.environ.update(env_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/Users/shu/Desktop/shuyherecode/llmkg/knowledge_graph/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"]=\"https://aigptx.top/v1/\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"\"\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")\n",
    "\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    KnowledgeGraphIndex,\n",
    "    ServiceContext,\n",
    ")\n",
    "\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "from llama_index import set_global_service_context\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "\n",
    "# define LLM\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, chunk_size=512)\n",
    "\n",
    "# set global service context\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ngql\n",
    "connection_string = f\"--address {os.environ['GRAPHD_HOST']} --port 9669 --user root --password {os.environ['NEBULA_PASSWORD']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Pool Created\n",
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rag_workshop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rag_workshop_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name\n",
       "0    rag_workshop\n",
       "1  rag_workshop_1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql {connection_string}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql CREATE SPACE IF NOT EXISTS rag_workshop_1(vid_type=FIXED_STRING(256), partition_num=1, replica_factor=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rag_workshop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rag_workshop_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name\n",
       "0    rag_workshop\n",
       "1  rag_workshop_1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql SHOW SPACES;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "USE rag_workshop_1;\n",
    "CREATE TAG IF NOT EXISTS entity(name string);\n",
    "CREATE EDGE IF NOT EXISTS relationship(relationship string);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql CREATE TAG INDEX IF NOT EXISTS entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %ngql USE rag_workshop; CLEAR SPACE rag_workshop; # clean graph space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NEBULA_USER'] = os.environ[\"NEBULA_USER\"]\n",
    "os.environ['NEBULA_PASSWORD'] = os.environ[\"NEBULA_PASSWORD\"]\n",
    "os.environ['NEBULA_ADDRESS'] = os.environ[\"NEBULA_ADDRESS\"]\n",
    "\n",
    "space_name = \"rag_workshop_1\"\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\"relationship\"]\n",
    "tags = [\"entity\"]\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KG Building with Llama Index\n",
    "\n",
    "from llama_index import download_loader\n",
    "\n",
    "WikipediaReader = download_loader(\"WikipediaReader\")\n",
    "\n",
    "loader = WikipediaReader()\n",
    "\n",
    "documents = loader.load_data(pages=['Guardians of the Galaxy Vol. 3'], auto_suggest=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id_='8e4ecab3-0a9b-48fd-a190-c188bc0908aa', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='17f45b107c8d43468ffd50200b327be922190646dbd5f8f7d61f152be0d46235', text='Guardians of the Galaxy Vol. 3 (stylized in marketing as Guardians of the Galaxy Volume 3) is a 2023 American superhero film based on the Marvel Comics superhero team Guardians of the Galaxy, produced by Marvel Studios, and distributed by Walt Disney Studios Motion Pictures. It is the sequel to Guardians of the Galaxy (2014) and Guardians of the Galaxy Vol. 2 (2017), and the 32nd film in the Marvel Cinematic Universe (MCU). Written and directed by James Gunn, it features an ensemble cast including Chris Pratt, Zoe Saldaña, Dave Bautista, Karen Gillan, Pom Klementieff, Vin Diesel, Bradley Cooper, Will Poulter, Sean Gunn, Chukwudi Iwuji, Linda Cardellini, Nathan Fillion, and Sylvester Stallone. In the film, the Guardians must save Rocket\\'s (Cooper) life from the High Evolutionary (Iwuji).\\nGunn stated in November 2014 that he had initial ideas for a third and final film in the series, and announced his return to write and direct in April 2017. Disney fired him from the film in July 2018 following the resurfacing of controversial posts on Twitter, but the studio reversed course by that October and reinstated him. Gunn\\'s return was publicly revealed in March 2019, with production resuming after he completed work for DC on The Suicide Squad (2021) and the first season of its spin-off series Peacemaker (2022). Filming began in November 2021 at Trilith Studios in Atlanta, Georgia, and lasted until May 2022.\\nGuardians of the Galaxy Vol. 3 premiered at Disneyland Paris on April 22, 2023, and was released in the United States on May 5, as part of Phase Five of the MCU. Like its predecessors, it was a critical and commercial success, with many deeming it to be a satisfactory conclusion to the trilogy. It grossed over $845.6 million worldwide, becoming the fourth-highest-grossing film of 2023. At the 96th Academy Awards, the film was nominated for Best Visual Effects.\\n\\n\\n== Plot ==\\nAt their new headquarters on Knowhere, the Guardians of the Galaxy are attacked by Adam Warlock, a Sovereign warrior created by High Priestess Ayesha who seeks to destroy them for stealing from her. After critically wounding Rocket, Adam is stabbed by Nebula and flees. The Guardians\\' med-packs are ineffective at healing Rocket\\'s wounds, due to a kill switch embedded in him by the organization Orgocorp. The Guardians travel to Orgocorp\\'s headquarters to find the switch\\'s override code and save Rocket\\'s life.\\nAs Rocket lies unconscious, he recalls his past. He was found as a baby raccoon and was experimented on by the High Evolutionary, Orgocorp\\'s leader, who sought to enhance and anthropomorphize animal lifeforms (Humanimals) to create an ideal society called Counter-Earth. Rocket befriended his fellow Batch 89 test subjects: the otter Lylla, the walrus Teefs, and the rabbit Floor. The High Evolutionary was impressed by Rocket\\'s growing intelligence and used his insight to fix a defect in later Humanimal batches, but planned to harvest Rocket\\'s brain for further research and exterminate the obsolete Batch 89. Rocket attempted to free his friends, but the High Evolutionary killed Lylla and mocked Rocket for showing grief over her death. Enraged, Rocket mauled the High Evolutionary, whose henchmen killed Teefs and Floor in the ensuing firefight. Rocket fled in a spaceship.\\nIn the present, the Ravagers, including an alternate version of Gamora, help the Guardians infiltrate Orgocorp. They retrieve Rocket\\'s file but discover that the code was removed, with the likely culprit being Theel, one of the High Evolutionary\\'s advisors. The Guardians, along with Gamora, depart for Counter-Earth to find him. They are followed by Ayesha and Adam after the High Evolutionary, their race\\'s creator, threatened to wipe out the Sovereign if they fail to retrieve Rocket. The Guardians reach Counter-Earth and are guided to the Arête Laboratories complex. Drax and Mantis remain with Gamora and Rocket, while Peter Quill, Groot, and Nebula travel to Arête. Nebula is forced to wait outside by guards due to her cybernetic enhancements; Quill and Groot enter Arête, while Drax tricks Mantis into pursuing Quill\\'s group. Gamora saves Rocket from Adam and the High Evolutionary\\'s guard War Pig.\\nQuestioned by Quill, the High Evolutionary admits this version of Counter-Earth\\'s society is imperfect, so he bombards the planet, killing the Humanimals as well as Ayesha. Arête departs as a spaceship, with Nebula, Drax, and Mantis boarding to rescue Quill and Groot. However, the latter pair escape Arête with Theel, who they kill before retrieving the code from his corpse. They are rescued by Gamora in their ship. As Quill\\'s group uses the code, Rocket flatlines and has a near-death experience in which he reunites with Lylla, Teefs, and Floor. He learns from Lylla that his time has not yet come, as Quill uses the code to disable the kill switch and restart Rocket\\'s heart.\\nDrax, Nebula, and Mantis encounter several genetically modified humanoid children on Arête, the High Evolutionary\\'s next batch of test subjects, before being captured. The other Guardians stage a rescue, leading to a battle against the High Evolutionary\\'s forces. Kraglin fires on Arête with Knowhere and then helps to save Knowhere\\'s citizens from a counter-attack by the High Evolutionary\\'s Hellspawn. Intent on retreat, the High Evolutionary\\'s crew mutiny but are killed by their leader. Drax, Nebula, and Mantis befriend three monstrous Abilisks to escape and reunite with Quill\\'s group. The Guardians delay leaving Arête, choosing to rescue the children who escape to Knowhere via a tunnel constructed by Cosmo\\'s telekinesis. Rocket discovers imprisoned animals on the ship and is confronted by the High Evolutionary, whom the other Guardians defeat. Rocket spares the High Evolutionary, and the Guardians help the animals escape to Knowhere. Quill nearly dies trying to cross over from Arête to Knowhere, but is saved by Adam who had earlier been rescued from the destruction of Arête by Groot.\\nQuill decides to leave the Guardians, names Rocket as the new captain, and reunites with his grandfather on Earth. Mantis embarks on a journey of self-discovery with the Abilisks, Gamora rejoins the Ravagers, and Nebula and Drax remain on Knowhere to raise the rescued children. In a mid-credits scene, the new Guardians—Rocket, Groot, Kraglin, Cosmo, Adam, Phyla (one of the rescued children), and Adam\\'s pet Blurp——take on a mission. \\n\\n\\n== Cast ==\\nChris Pratt as Peter Quill / Star-Lord:The half-human, half-Celestial leader of the Guardians of the Galaxy who was abducted from Earth as a child and raised by a group of alien thieves and smugglers, the Ravagers. In the film, Quill is in a \"state of depression\" following the appearance of a variant of his dead lover Gamora, who does not share the same affection for Quill as her older version had for him, which in turn affects his leadership of the Guardians.\\nZoe Saldaña as Gamora:An orphan who seeks redemption for her past crimes, and was adopted and trained by Thanos to be his personal assassin. The original version of Gamora, a member of the Guardians, was killed by Thanos in Avengers: Infinity War (2018), and an alternate version of the character traveled to the present in Avengers: Endgame (2019); Saldaña reprises the latter role in this film, now serving as a member of the Ravagers. Saldaña stated that Vol. 3 would be the final time she would portray Gamora, noting that she originally signed to play her in one film and ended up playing the role for much longer, a role she was grateful to play due to the impact it especially had on female fans.\\nDave Bautista as Drax the Destroyer:A member of the Guardians and a highly skilled warrior whose family was slaughtered by Ronan the Accuser, under the instructions of Thanos. Bautista stated that Vol. 3 would be the final time he would portray Drax, having been grateful for the role, while still calling it a \"relief\" to have concluded his time with the character, given the long hours needed to get into makeup and hoping to pursue more dramatic acting roles. Because of Bautista\\'s decision, Gunn opted not to include Drax in the post-credits scene.\\nKaren Gillan as Nebula:A member of the Guardians, a former Avenger, and Gamora\\'s adoptive sister who, similarly to her, was trained by their adoptive father Thanos to be his personal assassin. Gillan believed Nebula was developing into a \"slightly different person\" with more levity as she starts to heal psychologically following the death of Thanos, who was the source of her abuse and torment. Vol. 3 fulfills a character arc for the character writer and director James Gunn envisioned when starting work on Guardians of the Galaxy (2014), going from a minor villain to a member of the Guardians. Although the film teases a possible romance between Star-Lord and Nebula, Gunn denies having ever considered the two becoming a couple, though Gillan does believe she harbors a small crush on Quill.\\nPom Klementieff as Mantis: A member of the Guardians with empathic powers, and Quill\\'s half-sister.\\nVin Diesel as Groot: A member of the Guardians who is a tree-like humanoid and the accomplice of Rocket. Austin Freeman provided the motion-capture for Groot.\\nBradley Cooper as Rocket:A member of the Guardians and a former Avenger who is a genetically engineered raccoon-based bounty hunter and a master of weapons and military tactics. Gunn said that the film tells Rocket\\'s story, including his background and \"where he\\'s going\", along with how that ties into the other Guardians and the end of this iteration of the team. The film completes a character arc that was established in Guardians of the Galaxy and Guardians of the Galaxy Vol. 2 (2017), and continued in Infinity War and Endgame. Sean Gunn once again provided on set motion capture for the character, while also voicing young Rocket. Cooper also voiced adolescent Rocket while Noah Raskin voiced baby Rocket.\\nWill Poulter as Adam Warlock:A powerful artificial being created by the Sovereign to destroy the Guardians. Given Warlock is newly born from the Sovereign\\'s cocoon, he is \"basically a baby\" that \"does not understand life very well\". Poulter believed there was \"a lot of comedy\" in someone just entering the world for the first time and \"trying to develop his moral compass\", while also having \"some genuine pathos\". Gunn thought Warlock\\'s interactions with the Guardians provided \"an interesting juxtaposition\" to what their journey has been, and described him as a more traditional superhero compared to the Guardians, although not necessarily a hero.\\nSean Gunn as Kraglin: A member of the Guardians and Yondu Udonta\\'s former second-in-command in the Ravagers.\\nChukwudi Iwuji as the High Evolutionary:An alien cyborg scientist and CEO of OrgoCorp specializing in creating hybrid creatures and Rocket\\'s creator, seeking to forcibly enhance all living beings into a \"special race\" where he has been credited as creating the Animen, the Humanimals, the Hell Spawn, the Sovereign, the Xeronians, and the Star Children. Iwuji described the character as \"narcissistic, sociopathic, but very charming\", adding that there was \"something very Shakespearean about him, there\\'s something very emotionally dark about him, and he\\'s a lot of fun on top of all that\". In preparation for the role, Iwuji listened to his character\\'s taste for classical music in contrast to the American rock and pop music songs played in the film, allowing Iwuji to go back to his favorite arias and operas, like Wolfgang Amadeus Mozart\\'s The Marriage of Figaro (1786) and Don Giovanni (1787). Gunn likened the High Evolutionary to \"a space version\" of Doctor Moreau from Island of Lost Souls (1932), a film Gunn is a big fan of, calling him \"a detestable character\". When asked by Rachel Lindsay of Extra about the character, Gunn referred to the High Evolutionary as the \"cruelest MCU villain\" to date the franchise has ever seen due to how he negatively impacts on the lives of Rocket and his fellow subject friends, while Iwuji made sure along with Gunn to avoid giving the Evolutionary, at least intentionally, any sympathy unlike previous villains like Thanos or Killmonger, focusing under Gunn\\'s orders on commenting in the character\\'s single mindedness, narcissistic and zealous personality like the \"most horrific\" figures in history have been shown to be.\\nLinda Cardellini as Lylla: An anthropomorphic otter who is an associate and friend of Rocket. Cardellini provided both the voice and motion capture for Lylla, having previously played Laura Barton in past MCU media.\\nNathan Fillion as Master Karja: An orgosentry at Orgocorp.\\nSylvester Stallone as Stakar Ogord: A high-ranking Ravager.Reprising their respective roles from previous Guardians films and/or The Guardians of the Galaxy Holiday Special (2022) are Elizabeth Debicki as Ayesha, the golden High Priestess and the leader of the Sovereign people who had Adam Warlock created to destroy the Guardians; Michael Rosenbaum as Martinex, a high-ranking Ravager; Seth Green as the voice of Howard the Duck; Christopher Fairbank as the Broker; Stephen Blackehart and Rhett Miller as Steemie and Bzermikitokolok, two denizens of Knowhere; Gregg Henry as Quill\\'s grandfather Jason; and Michael Rooker as Yondu Udonta, the former head of the Ravagers and Peter\\'s deceased mentor. Maria Bakalova reprises her voice and motion capture role from the Holiday Special as Cosmo, a member of the Guardians who is a sapient dog that developed psionic abilities after being abandoned in outer space by the Soviet Union. Gunn changed Cosmo\\'s gender from male, as depicted in the comics, to female for the film, as a tribute to the character\\'s original inspiration, Laika, a Soviet space dog who became one of the first animals in space. Cosmo was physically portrayed by dog actor Slate, after also doing so for the Holiday Special, and was previously portrayed by dog actor Fred in the first two Guardians films. Tara Strong (who voiced Miss Minutes in the Disney+ series Loki) voices Mainframe who was previously voiced by an uncredited Miley Cyrus in Vol. 2. Jared Gore provides motion capture for Krugarr, a Ravager who wields sorcery powers and speaks through his sorcery.Asim Chaudhry voices Teefs, an anthropomorphic walrus; Mikaela Hoover (who played Nova Prime\\'s assistant in the first film) voices Floor, an anthropomorphic rabbit; Daniela Melchior appears as Ura, the receptionist at Orgocorp; Miriam Shor and Nico Santos appear as Recorder Vim and Recorder Theel, respectively, the scientifically minded henchmen of the High Evolutionary; Jennifer Holland appears as Administrator Kwol, a security employee of Orgocorp; Kai Zen appears as Phyla, one of the High Evolutionary\\'s Star Child prisoners; Judy Greer (who played Maggie Lang in the first two Ant-Man films) voices War Pig, a cyborg pig and member of the Hell Spawns working for the High Evolutionary; Reinaldo Faberlle voices Behemoth, a cyborg bird and member of the Hell Spawns who also works for the High Evolutionary; Dee Bradley Baker voices Blurp, a furry F\\'saki that is an unnamed Ravager\\'s pet; and Dane DiLiegro appears as an Humanimal octopus drug dealer on Counter-Earth (credited as \"Unsavory Octopus\").Cameos in the film include Lloyd Kaufman as Gridlemop, a Krylorian on Knowhere who partakes in a card game with Kraglin; Pete Davidson as Phlektik, a guard at Arête Laboratories; Molly C. Quinn as a Ravager; and writer and director James Gunn as the voice of Lambshank, a deformed experiment of the High Evolutionary that is among those freed by the Guardians of the Galaxy.\\n\\n\\n== Production ==\\n\\n\\n=== Development ===\\n\\n\\n==== Initial work ====\\nGuardians of the Galaxy (2014) writer and director James Gunn stated in November 2014 that, in addition to having the \"basic story\" for Guardians of the Galaxy Vol. 2 (2017) while working on the first film, he also had ideas for a potential third film. Despite this, he was unsure in June 2015 if he would be involved with a third Guardians film, saying that it would depend on how he felt after making Vol. 2. In April 2016, Marvel Studios president Kevin Feige, the producer of the Guardians films, said a third film was planned for the franchise as part of the Marvel Cinematic Universe (MCU) in \"2020 and beyond\". In March 2017, Gunn said there would be a third film \"for sure. We\\'re trying to figure it out\", soon adding that there were no specific plans for the film yet, but that Marvel would want to make it \"unless something goes horribly—which is always possible, you never know\". He also reiterated that he had not decided whether he would be directing the film, and that he was going to figure out his involvement and his next project \"over the next couple of weeks\". Part of Gunn\\'s reluctance to return to the franchise came from not wanting to work on it without Michael Rooker, whose character from the first two films, Yondu Udonta, died at the end of Vol. 2.\\n\\nGunn announced in April 2017 that he would return to write and direct Guardians of the Galaxy Vol. 3. He said the film would be set after Avengers: Infinity War (2018) and Avengers: Endgame (2019), and would \"conclude the story of this iteration of the Guardians of the Galaxy, and help catapult both old and new Marvel characters into the next ten years and beyond\". He also felt that the three Guardians films would \"work together as a whole\", telling one story, with the third film \"tying a lot of stuff together\" from the first two and giving \"a lot of answers on a lot of different things\". Gunn also planned to work with Marvel on the future of the \"Marvel Cosmic Universe\". He was set to begin work on Vol. 3 shortly after completing his work as executive producer and consultant on Infinity War. On returning for the third film, Gunn said, \"I wouldn\\'t have said yes if I didn\\'t have a fairly clear idea of where we were going and what we were going to do. I\\'m not a guy that\\'s just going to do it if I don\\'t have a vision for it\".After originally including Adam Warlock in his script treatment for Vol. 2, Gunn and Feige noted the importance of the character on the cosmic side of the MCU and hinted that he would make an appearance in Vol. 3. In May 2017, after the release of Vol. 2, Gunn said he would be creating the third film \"over the next three years\", and confirmed that Pom Klementieff would reprise her role as Mantis. He also intended to have Elizabeth Debicki reprise her role as Ayesha. By mid-June, Gunn had completed the first draft of his script treatment for the third film, and was considering changing a piece of character info he had placed in the background of the mugshot sequence in the first film (when the Guardians are captured by the Nova Corps). In September, Gunn reiterated that Vol. 3 would be released \"in a little under three years\", as the film had privately been set for release on May 1, 2020. At the end of February 2018, Gunn planned to meet with Mark Hamill about possibly appearing in the film. In April, Chris Pratt was set to reprise his role as Peter Quill / Star-Lord, and the following month, Dave Bautista confirmed that he would reprise his role as Drax the Destroyer. Marvel received the completed first draft of the screenplay from Gunn by the end of June, ahead of the beginning of official pre-production on the film.\\n\\n\\n==== Firing of James Gunn ====\\nOn July 20, 2018, Disney and Marvel severed ties with Gunn. This came after conservative commentators, such as Mike Cernovich, began circulating old tweets he had made regarding controversial topics such as rape and pedophilia, and called for his firing. The Walt Disney Studios chairman Alan F. Horn stated, \"The offensive attitudes and statements discovered on James\\' Twitter feed are indefensible and inconsistent with our studio\\'s values, and we have severed our business relationship with him\". While not part of the decision to fire Gunn, the Walt Disney Company CEO Bob Iger supported the \"unanimous decision\" from the various executives at Marvel and Walt Disney Studios. In response, Gunn said in a series of tweets that when he started his career he was \"making movies and telling jokes that were outrageous and taboo\" but felt as he has \"developed as a person, so has my work and my humor\". He continued, \"It\\'s not to say I\\'m better, but I am very, very different than I was a few years ago; today I try to root my work in love and connection and less in anger. My days saying something just because it\\'s shocking and trying to get a reaction are over\". In a separate statement, Gunn said the tweets at the time were \"totally failed and unfortunate efforts to be provocative\", adding \"I understand and accept the business decisions taken today. Even these many years later, I take full responsibility for the way I conducted myself then\".\\nIn response to the firing, many of the Guardians cast members tweeted support for Gunn. Rooker decided to leave Twitter, while fans signed an online petition asking for Gunn to be reinstated which received over 300,000 signatures. The firing also garnered reaction from other Hollywood personalities, such as actress Selma Blair and comedian Bobcat Goldthwait, and inspired opinion pieces on the firing and how it would affect Hollywood from Kareem Abdul-Jabbar, and news organizations such as The Hollywood Reporter, Variety, Deadline Hollywood, and Forbes. On July 30, the cast of the Guardians of the Galaxy films, including Pratt, Zoe Saldaña, Bautista, Bradley Cooper, Vin Diesel, Sean Gunn, Klementieff, Rooker, and Karen Gillan, issued a statement in support of James Gunn, saying, \"We fully support James Gunn. We were all shocked by his abrupt firing last week and have intentionally waited these ten days to respond in order to think, pray, listen, and discuss. In that time, we\\'ve been encouraged by the outpouring of support from fans and members of the media who wish to see James reinstated as director of Volume 3 as well as discouraged by those so easily duped into believing the many outlandish conspiracy theories surrounding him\". Despite this and the notable \"vociferous support\" Gunn received, Variety reported that Disney was not planning to rehire him as the jokes were \"unacceptable in the #MeToo era and are not in line with Disney\\'s family-friendly image\". Variety continued that, despite rumors of Gunn being replaced by established Marvel directors such as Jon Favreau, Taika Waititi, or the Russo brothers, Marvel had yet to meet with any other director, and would most likely hire someone new. In early August, Bautista said that he would fulfill his contract and appear in the film as long as Marvel chose to use Gunn\\'s existing script.Disney and Marvel still wanted to \"move forward quickly\" on the film, and were soon confirmed to be keeping Gunn\\'s script. This, combined with the fact that Gunn did not breach his contract since the tweets were written years before he signed on to the film, had led to \"complicated negotiations\" between Gunn and Disney over his exit settlement. Gunn was expected to be paid $7–10 million or more, and there was some hope that the negotiations could lead to him eventually returning in some capacity, \"even if [it was] to develop and direct another Marvel movie\". Gunn would be free to move on to new projects following the settlement, and other major studios were interested in hiring him including Warner Bros. for their rival superhero franchise, the DC Extended Universe (DCEU). During this time, executives at Marvel Studios began \"back channel conversations\" with Disney in an attempt to find a compromise that could lead to Gunn returning to the film in some way. This \"eleventh-hour\" effort from Marvel was inspired by the statements from the film\\'s cast. In mid-August, Gunn met with Horn following a strong push from Gunn\\'s talent agency for him to be given a second chance. Despite this and the reported \"civil and professional\" nature of the meeting, Horn only took it as a courtesy and used it to reaffirm Disney\\'s decision to fire Gunn.Later in August, the small crew that was preparing for pre-production were dismissed as production of the film was postponed so Marvel and Disney could find a director to replace Gunn. Pre-production was to have begun by the end of 2018, with principal photography set for January or February 2019. At this time, Bautista was unsure if he would return for the film, as he did not know if he would \"want to work for Disney\" given how they handled the firing of Gunn. In late September, James Gunn\\'s brother Sean, who played Kraglin Obfonteri and provided motion capture for Rocket in the previous Guardians films, reiterated that Disney still intended on making the film with James\\'s script, but had not revealed to the cast when production may continue. Sean added that he had been preparing to reprise his roles for the third film before his brother\\'s firing. At the end of the month, Cooper was asked if he would consider directing Vol. 3 after the success of his directorial debut A Star Is Born (2018), but said that he \"could never imagine\" directing a film that he did not write. By mid-October, James Gunn had completed his exit settlement with Disney and was set to write and potentially direct The Suicide Squad (2021) for Warner Bros / DC Films.\\n\\n\\n==== Rehiring Gunn ====\\nThe day after Gunn joined The Suicide Squad in mid-October 2018, he was privately notified by Horn that he could return as director for Vol. 3. This came after further meetings between the studios and Gunn. Horn had changed his mind after being impressed by Gunn\\'s response to the situation. Gunn discussed his commitments to The Suicide Squad with Feige, and production on Vol. 3 was put on hold until February 2021 to allow Gunn to complete The Suicide Squad first. In December, after working with Marvel Studios on the script for Ant-Man (2015), Adam McKay said he was willing to work with the studio again and stated that he had discussed taking over as director for Vol. 3 with Feige, among other projects. In early 2019, Feige and Pratt reiterated that Marvel would still make Vol. 3, and in March 2019, Gunn was publicly revealed to have been rehired as director of the film. Deadline Hollywood stated that Marvel Studios had \"never met with or considered any other director\" for the film. By the end of April, the franchise\\'s five main stars—Pratt, Saldaña, Bautista, Cooper, and Diesel—were all expected to return for the sequel, with filming to take place in 2020.Discussing his firing and re-hiring in May 2019, Gunn said that of all the elements of the film that he had been sad to leave when he was fired, the most meaningful to him was the character of Rocket. Gunn personally identifies with Rocket, describing himself and the character as \"the same\". He had actually grown to love the character since working on the first film due to feeling that an origin story for Rocket could justify what a Bugs Bunny-like \"goofy character\" like him could exist in the MCU if it were the saddest one in the universe, crediting it as the \"seed\" of the trilogy. While Vol. 3 effectively reveals Rocket\\'s backstory through flashbacks akin to those from the story structure of The Godfather Part II (1974), Gunn initially considered telling Rocket\\'s origins in a team-up movie between him and Groot without the other Guardians, but ultimately felt that he had to conclude Peter Quill\\'s story first and then focus on Rocket in a third Guardians-centric film. That month, Gillan confirmed that she was returning for the sequel and expressed excitement for Gunn\\'s return to the franchise. In June, Saldaña was asked about her role in the film after her character Gamora was killed in Infinity War, and she returned to play a younger version in Endgame who travels through time to the present. Saldaña said that Gamora\\'s fate would depend on the plans that Marvel and Gunn have for Vol. 3, but that she would like to see Gamora rejoin the Guardians and also be portrayed as \"the most lethal woman in the galaxy\" as she has been referred to previously. Gunn was asked in October if he was unhappy about Marvel\\'s decision to kill Gamora in Infinity War and said he was not, adding that he had discussed the storyline with the studio beforehand. According to Infinity War and Endgame screenwriters Christopher Markus and Stephen McFeely, Gamora was brought back in Endgame specifically so that Gunn could include her in Vol. 3, so Gunn found no complications over writing her character arc in Vol. 3 due to having been told in advance. In December, Gunn was asked if he would have Yondu return in the film and said as long as he was involved with the Guardians characters, he would not have the character be resurrected. Gunn felt the stakes of a character\\'s death were important and said characters who die in his films would likely remain dead. Gunn said in February 2020 that bringing Yondu back to life would \"nullify Yondu\\'s sacrifice\" in Vol. 2, and said the character would not return unless it was for a prequel or flashback; Gunn later said Yondu would not be resurrected in the film to not diminish his death\\'s meaning. In April, Gunn said the COVID-19 pandemic would not affect production plans for the film at that time, saying the next month that the film would be released \"a little after 2021\".In August 2020, Gunn turned in a new draft of the film\\'s script and began writing a spin-off television series from The Suicide Squad titled Peacemaker (2022). A month later, he was planning to begin work on Vol. 3 in 2021 after completing that film and series. He confirmed in November that the script for Vol. 3 was finished, and said that very little had changed from his initial ideas despite the production setbacks. The film was given a 2023 release date a month later, with filming set to begin in late 2021. Shortly after, it was revealed to also be set after The Guardians of the Galaxy Holiday Special (2022).\\n\\n\\n=== Pre-production ===\\nPre-production work creating the designs and visuals for the film began by April 2021. In early May, Marvel Studios announced that the film would be released on May 5, 2023. Later that month, Gunn said Vol. 3 would take place after the events of Thor: Love and Thunder (2022), which features several Guardians characters. That film concludes the storyline established in Endgame which sees Thor journey off with the Guardians. Gunn noted this ending was decided upon \"in editing\" and conflicted with his already-submitted screenplay for Vol. 3, since he never planned to feature Thor in the film. Gunn had begun storyboarding the film by June, with filming later revealed to begin in November 2021 in Atlanta, Georgia for an expected end around April 2022. By then, Bautista said he had not read a script for Vol. 3 and was unsure if it had changed during the production delays. The next month, Gillan said that she and Klementieff had read the script together and she found it to be incredible, brilliant, emotional and funny. She also felt it was Gunn\\'s \"strongest work yet\" with the Guardians characters. Gunn reiterated that the script had \"basically stayed the same\" from three years prior but he had been \"playing with it in little ways\" over the years. He was in the middle of another draft by the end of the month and said the film would be emotional and have a \"heavier\" story than the previous films, with a more grounded approach that was inspired by The Suicide Squad and Peacemaker. An early option Gunn had in mind for the character who would become the film\\'s main villain and be revealed to be the one who created Rocket was the Fantastic Four villain Annihilus, but Gunn ultimately opted to fill that role with the High Evolutionary. Gunn originally wrote a cameo appearance for Kumail Nanjiani, a friend of his, but removed this after learning Nanjiani was cast as Kingo in Marvel Studios\\' Eternals (2021).By late August, Gunn and Marvel Studios began meeting with actors for the role of Adam Warlock, including Will Poulter. George MacKay was also on the shortlist and Regé-Jean Page was considered for the part. Poulter auditioned for the role over Zoom before an in-person screen test with Gunn in Atlanta. When first auditioning for Warlock, Poulter was unaware of who his character\\'s name was other than he had been teased at the post-credits scene of Vol. 2, but Marvel just described the role to him as \"an untitled character\" until Poulter was \"drip-fed\" with more information over and over until discovering how steeped Adam Warlock is in the source material. In September, Gillan reiterated her positive comments about the script and said the film would explore the characters from the previous Guardians films on a deeper level, while Seth Green, who voices Howard the Duck in the MCU, said the film would be about Gamora and Nebula\\'s story. He did not know at that time if Howard would appear after doing so in the previous Guardians films. Poulter was cast as Adam Warlock in October, and Gunn said \"dozens of roles\" had already been cast. Poulter was chosen for the part because of his dramatic and comedic abilities and because Gunn \"wanted somebody who was youthful\" and would fit with Marvel Studios\\' future plans for the character. Casting also took place for various background roles, including aliens and security guards. Pratt began rehearsals and camera tests later that month, and a production meeting was held in early November, shortly before the start of filming. Gunn also reiterated his comments on not resurrecting Yondu in the film.\\n\\n\\n=== Filming ===\\nPrincipal photography began on November 8, 2021, at Trilith Studios in Atlanta, Georgia, under the working title Hot Christmas. Henry Braham serves as cinematographer, after doing so for Vol. 2, The Suicide Squad,  and The Guardians of the Galaxy Holiday Special. Filming was previously scheduled to begin in January or February 2019 prior to Gunn\\'s firing, and then in February 2021, before Gunn began work on Peacemaker. With the start of filming, Sylvester Stallone revealed that he would return as Stakar Ogord from Vol. 2, and Gunn posted a photo of the main cast members which revealed that Chukwudi Iwuji was part of the film following his collaboration with Gunn on Peacemaker. Iwuji\\'s screen test for the film was shot on the set of Peacemaker with that series\\' crew, and Marvel repaid this favor by letting Gunn use the Vol. 3 set and crew to film Ezra Miller\\'s cameo appearance as Barry Allen / The Flash for the Peacemaker season finale.Production designer Beth Mickle said Gunn chose to mainly use practical effects for Vol. 3 after they did so with their work on The Suicide Squad. In February 2021, Gunn stated the film would be shot using Industrial Light & Magic\\'s StageCraft virtual production technology that was developed for the Disney+ Star Wars series The Mandalorian, but in October, he said they would not be able to use the technology because the sets were too big, believing they were larger than the sets used on The Suicide Squad. The interior of the Guardians\\' new ship, the Bowie, was a four-story set. Judianna Makovsky serves as costume designer. The Guardians of the Galaxy Holiday Special was filmed at the same time as Vol. 3, from February to late April 2022, with the same main cast and sets. Gunn enjoyed being able to switch to filming the special after doing scenes for Vol. 3, given the tonal difference between the two with Vol. 3 being more \"emotional\", feeling it helped provide a \"relief\" to the actors as well, and called the Holiday Special shoot easier than Vol. 3. In February 2022, Callie Brand was revealed to appear in the film as an alien. Shooting was also expected to occur in London, England, in late 2021. Vol. 3 is the first MCU film to feature the word \"fuck\" uncensored; it is spoken by Quill. The dialogue \"Open the fucking door\" was not scripted, but improvised by Pratt on Gunn\\'s suggestion, though there was some consideration over giving the one-liner to Groot instead. Gunn mentioned that the Korean film The Villainess (2017) inspired one of the fight scenes in Vol. 3. Filming on Vol. 3 wrapped on May 6, 2022.\\n\\n\\n=== Post-production ===\\nIn early June 2022, Daniela Melchior was revealed to have a small role in the film, after previously starring in The Suicide Squad. Debicki was also confirmed to be reprising her role as Ayesha, while Maria Bakalova and Nico Santos were also revealed to be appearing in the film. In July, Iwuji and Bakalova were revealed to be portraying the High Evolutionary and Cosmo the Spacedog, respectively. Cosmo was physically portrayed by dog actor Fred in the first two Guardians films, and Slate in the Holiday Special and Vol. 3. The following month, Michael Rosenbaum revealed that he had reprised his role as Martinex from Vol. 2 in the film. In October 2022, it was revealed that Bakalova would portray Cosmo in the Holiday Special ahead of her role in Vol. 3. In February 2023, Asim Chaudhry revealed he would appear in the film in an undisclosed role. In April 2023, Linda Cardellini was revealed to be voicing Lylla; she previously appeared in multiple MCU projects as Laura Barton, and starred as Velma Dinkley in the Gunn-written films Scooby-Doo (2002) and Scooby-Doo 2: Monsters Unleashed (2004), as well as a cameo in the Gunn-written and directed Super (2010). Two days of reshoots occurred. In late April, Tara Strong revealed that she was cast in an undisclosed role. Strong was later revealed to have been cast as Mainframe, replacing Miley Cyrus from Vol. 2 due to Cyrus\\' unavailability.The visual effects were provided by Framestore, Weta FX, Sony Pictures Imageworks, Industrial Light & Magic, Rodeo FX, Rise FX, Crafty Apes, BUF, Lola VFX, Perception, and Compuhire. Stephane Ceretti returns from the first film to serve as the visual effects supervisor, while Fred Raskin returns from the first two films to serve as the editor, alongside Greg D\\'Auria, who returns from the Holiday Special. Additional editing was provided by Tatiana S. Riegel.\\n\\n\\n== Music ==\\n\\nIn April 2017, Gunn felt the music for the film would be different from what was used for the first two films\\' soundtracks, Awesome Mix Vol. 1 and Vol. 2. The next month, he added that he was \"panicking\" about the soundtrack and had to make some \"pretty specific choices\" shortly due to the wider range of available music for the story, By early July 2017, Gunn had narrowed down his choices for potential songs to 181, but noted that this list could grow again. All of the songs for the film had been selected by the following month; the songs are not modern and come from Quill\\'s Zune that he received at the end of Vol. 2, although Gunn added that the soundtrack was not limited to 1970s pop songs compared to the first two films, instead spanning multiple decades. Gunn was unable to use the song \"Russian Roulette\" by the Lords of the New Church for Vol. 3 due to a legal battle over its ownership. The film opens with an acoustic version of \"Creep\" by Radiohead, which provided \"a much different tone from the beginning than the other two films\". The film ends with \"Dog Days Are Over\" by Florence and the Machine, as Gunn is a fan of its album Lungs; he had thought about including the song to wrap-up the trilogy since he started writing Vol. 2.The track list for Awesome Mix Vol. 3 was revealed in April 2023, and was made available on Spotify and Apple Music on April 3 as part of a larger Guardians of the Galaxy: The Official Mixtape playlist, which also featured the soundtracks and scores from the previous two films. Awesome Mix Vol. 3 was released by Hollywood Records on CD and digital download on May 3, 2023, a 12\" 2-LP vinyl on May 5, and is set to release on cassette on July 7.In October 2021, Gunn revealed that John Murphy was composing the film\\'s score and had already recorded music to be played on set during filming. Murphy replaces Tyler Bates, who composed the score for the first two films. However, Bates\\' theme from the previous films were referenced; Murphy had also replaced Bates as composer of The Suicide Squad after Bates left that film during production. Murphy\\'s original score for the film was released digitally on May 3, 2023.\\n\\n\\n== Marketing ==\\nThe film was discussed during Marvel Studios\\' panel at the 2022 San Diego Comic-Con, where the first footage was revealed. Iwuji was also announced as playing the High Evolutionary, appearing at the panel in costume. Gunn stated the footage was not released publicly because the visual effects were not complete enough for \"repeated views and close inspection\". An official trailer was released on December 1, 2022, during the CCXP. It featured \"In the Meantime\" by Spacehog. Drew Taylor of TheWrap called the trailer a doozy, thrilling, and emotional, and stated that \"Gunn\\'s patented, rollicking \\'Guardians of the Galaxy\\' tone is very much in place\", and noted \"an undercurrent of extreme melancholy\". Carson Burton of Variety predicted from the trailer that the film would be \"shaping up to be an emotional ending\" by showing Rocket\\'s memories and Star-Lord missing Gamora. Jay Peters at The Verge said the trailer intrigued him as a \"wild ride across the stars\" with different planets.A second trailer for the film was released during Super Bowl LVII on February 12, 2023. It featured \"Since You Been Gone\" by Rainbow. Grant Hermanns of Screen Rant felt the trailer gave \"a deeper look\" at the film, particularly Adam Warlock\\'s powers as compared to his brief appearance in the first one. Hermanns also said the second trailer \"goes a step further in highlighting the emotional story\" after the first one \"efficiently set [the film\\'s] tone, featuring plenty of melancholic shots of the [Guardians of the Galaxy] facing the music\". The trailer accumulated 134.1 million views across TikTok, Instagram, YouTube, Twitter, and Facebook, and was the most-watched Super Bowl trailer in post-game day traffic according to RelishMix. It was also the first time since the onset of the COVID-19 pandemic that a Super Bowl trailer exceeded 100 million views on social media in a 24-hour period.Disney and Marvel Music partnered with the music streaming service Spotify in May 2023, to promote the film. As part of the promotion, a playlist, titled the \"K-GOTG Radio Experience\", was created. Marvel Studios also promoted the film with General Mills limited-edition cereals and snacks, including Honey Nut Cheerios, Cookie Crisp, Lucky Charms, Trix, Reese\\'s Puffs, Cinnamon Toast Crunch, and Go-Gurt. Microsoft also partnered with Marvel Studios to promote the film with a limited-edition Zune MP3 player; a single non-functional model would be created using 3D printing and launched inside the International Space Station.\\n\\n\\n== Release ==\\n\\n\\n=== Theatrical ===\\nGuardians of the Galaxy Vol. 3 had an early screening at Dongdaemun Design Plaza on April 19, 2023. The film premiered at Disneyland Paris on April 22, 2023, and its North American premiere was held at the Dolby Theatre in Hollywood, Los Angeles, on April 27. The film was released in several countries including the United Kingdom on May 3, 2023, and in the United States on May 5. It was previously set for release on May 1, 2020, before it was dropped from that date. It is part of Phase Five of the MCU. It was released in 3D, IMAX, Dolby Cinema, 4DX, and ScreenX.Disney released over 600 unique versions of the film to theaters, including a version with variable aspect ratios. Forty-five minutes of the film was presented in the flat 1.85:1 aspect ratio, while the rest of the film is in the 2.39:1 letterboxed aspect ratio.\\n\\n\\n=== Home media ===\\nGuardians of the Galaxy Vol. 3 was released by Walt Disney Studios Home Entertainment on digital download on July 7, 2023; on Ultra HD Blu-ray, Blu-ray, and DVD on August 1; and on Disney+ on August 2, where an IMAX Enhanced version was also available. The film was the final physical media release for Walt Disney Studios Home Entertainment in Australia, as they decided to discontinue selling their films on physical home media there.\\n\\n\\n== Reception ==\\n\\n\\n=== Box office ===\\nGuardians of the Galaxy Vol. 3 has grossed $362 million in the United States and Canada, and $486.6 million in other territories, for a worldwide total of $848.6 million.In the US and Canada, Guardians of the Galaxy Vol. 3 was projected to gross around $110 million from 4,450 theaters in its opening weekend. The film made $48.2 million on its first day, including $17.5 million from Thursday night previews. It went on to debut with $118.4 million, topping the box office. In its second weekend, Guardians of the Galaxy Vol. 3 retained the top spot at the box office with $62 million, a 48% decline from its opening weekend and the best second-weekend hold of any sequel in the Marvel Cinematic Universe, and a notably smaller second-weekend decline than those of the franchise\\'s recent releases, including Ant-Man and the Wasp: Quantumania (70%), Thor: Love and Thunder (68%), and Doctor Strange in the Multiverse of Madness (67%). The film made $32 million in its third weekend, being dethroned by Fast X.Outside the US and Canada, the film grossed $168.1 million in its opening weekend. In its second weekend, the film grossed $92 million for a drop of 40% from its opening weekend. As of May 27, 2023, the highest grossing territories were China ($77.4 million), the United Kingdom ($36 million), Mexico ($30.8 million), South Korea ($26.7 million), and France ($24.3 million).\\n\\n\\n=== Critical response ===\\nThe review aggregator website Rotten Tomatoes reported an approval rating of 82% based on 403 reviews with an average rating of 7.2/10. The site\\'s critics consensus reads: \"A galactic group hug that might squeeze a little too tight on the heartstrings, the final Guardians of the Galaxy is a loving last hurrah for the MCU\\'s most ragtag family.\" On Metacritic, the film has a weighted average score of 64 out of 100, based on 63 critics, indicating \"generally favorable reviews\". Audiences polled by CinemaScore gave the film an average grade of \"A\" on an A+ to F scale, the same as the previous two Guardians films, while PostTrak reported that moviegoers gave the film a 91% positive score, with 79% saying they would definitely recommend it.The Independent found it was \"the best Marvel movie in years\" as did Vox and the CBC. In mixed reviews, Peter Bradshaw of The Guardian and Nicholas Barber of the BBC agreed the film was overlong, Barber opining that \"the film\\'s saving grace is that, just as Gunn has been allowed to unleash his gonzo imagination, he has also been allowed to pour out his emotions.\" Wendy Ide of The Observer lauded the films for its emotional weight and deemed it a satisfying conclusion, stating that \"What elevates Vol 3 (supposedly the final film in the GOTG series) is the way it keeps that personality, nodding to the irreverent swagger that is a crucial component of the Guardians USP while delivering a series of devastating emotional sucker punches along the way.\" Matt Singer from ScreenCrush praised the film for concluding Rocket\\'s arc story stating that \"a character tells Rocket that the events unfolding onscreen have been his story all along — and with Guardians of the Galaxy Vol. 3, it does feel like Marvel has spent $200 million on a movie about a melancholy space raccoon looking for love and acceptance.\" Writing for The Verge, Charles Pulliam-Moore praised the film\\'s action sequences and storyline and commented that \"Guardians of the Galaxy Vol. 3 tells the action-packed, flashback-filled story of how Rocket Raccoon\\'s (Bradley Cooper) life being gravely endangered gives the rest of the Guardians a reason to come together and really start working on some of the emotional issues that\\'ve been haunting them since Endgame.\" The Hindustan Times praised Gunn\\'s direction and writing, commenting that \"As James Gunn concludes his journey with these characters he clearly cares so deeply about, you can\\'t help but reflect on your own. Walking out, I had my own little flashback montage playing in my head of all the adventures we\\'ve been on and foes we\\'ve faced with this lovable group of galaxy-saving idiots.\" Nathan Durr of CBS News praised the film\\'s soundtrack and stated that \"There\\'s no exception here regarding the soundtrack as Gunn and company cleverly implement songs that add weight to the complexities and emotions of the characters.\"A negative review from NPR criticized the approach of cruelty to animals in the film while The New York Times called it a \"dour, visually off-putting two-and-a-half-hour A.S.P.C.A. nightmare of a film (that) may only be for completionist fans\", and the Chicago Tribune, \"the most empty, brutal MCU movie yet\". Conversely, People for the Ethical Treatment of Animals (PETA) declared the film to be \"the best animal rights film of the year\", and gave Gunn a \"Not a Number Award\" for his depiction of animal testing.\\n\\n\\n=== Accolades ===\\n\\n\\n== Documentary special ==\\n\\nIn February 2021, the documentary series Marvel Studios: Assembled was announced. The special on this film, \"The Making of Guardians of the Galaxy Vol. 3\", was released on Disney+ on September 13, 2023.\\n\\n\\n== Future ==\\nGunn said in April 2017 that a fourth Guardians film could happen, though it would likely center on a new group of characters since Gunn planned to conclude the story of the current team in Vol. 3. Later in September, Gunn said he was unlikely to return for another Guardians film but would continue to work with Marvel Studios on other projects that use the Guardians and cosmic characters. One such project from Gunn was a film centered on Drax and Mantis, which Bautista called \"brilliant\". However, in May 2021, Bautista stated that he had not heard any further updates regarding it, feeling Marvel Studios was not \"very interested, or it doesn\\'t fit into the way they have things mapped out\". Gunn confirmed in September 2019 that he intended for Vol. 3 to be his last Guardians film, which he reaffirmed in May 2021. In July 2021, Gillan expressed her desire to continue playing Nebula after Vol. 3. In April 2023, Saldaña confirmed that Vol. 3 would be the last time she portrays Gamora, but hoped Marvel would recast the role with a younger actor because she wished for the character to continue. The following month, Pratt indicated his willingness to continue playing Peter Quill in the future if the right script came along, and a note at the end of Vol. 3\\'s post-credits scene states that the \"Legendary Star-Lord\" would return to the MCU.\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== External links ==\\n\\nOfficial website  at Marvel.com\\nGuardians of the Galaxy Vol. 3 at IMDb', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kg_index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kg_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mkg_index\u001B[49m\u001B[38;5;241m.\u001B[39mstorage_context\u001B[38;5;241m.\u001B[39mpersist(persist_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./storage_graph\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'kg_index' is not defined"
     ]
    }
   ],
   "source": [
    "kg_index.storage_context.persist(persist_dir='./storage_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docstore.json     index_store.json  vector_store.json\n"
     ]
    }
   ],
   "source": [
    "!ls storage_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "## Restore storage_context from disk\n",
    "from llama_index import load_index_from_storage\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir='./storage_graph', graph_store=graph_store)\n",
    "kg_index = load_index_from_storage(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    max_triplets_per_chunk=10,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.indices.knowledge_graph.base.KnowledgeGraphIndex object at 0x7f8d39ae67d0>\n"
     ]
    }
   ],
   "source": [
    "print(kg_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text2Cypher\n",
    "from llama_index.query_engine import KnowledgeGraphQueryEngine\n",
    "\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.graph_stores import NebulaGraphStore\n",
    "\n",
    "nl2kg_query_engine = KnowledgeGraphQueryEngine(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=llm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host</th>\n",
       "      <th>Port</th>\n",
       "      <th>Status</th>\n",
       "      <th>Leader count</th>\n",
       "      <th>Leader distribution</th>\n",
       "      <th>Partition distribution</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>storaged0</td>\n",
       "      <td>9779</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>0</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>storaged1</td>\n",
       "      <td>9779</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>0</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>No valid partition</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>storaged2</td>\n",
       "      <td>9779</td>\n",
       "      <td>ONLINE</td>\n",
       "      <td>2</td>\n",
       "      <td>rag_workshop:1, rag_workshop_1:1</td>\n",
       "      <td>rag_workshop:1, rag_workshop_1:1</td>\n",
       "      <td>3.6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Host  Port  Status  Leader count               Leader distribution  \\\n",
       "0  storaged0  9779  ONLINE             0                No valid partition   \n",
       "1  storaged1  9779  ONLINE             0                No valid partition   \n",
       "2  storaged2  9779  ONLINE             2  rag_workshop:1, rag_workshop_1:1   \n",
       "\n",
       "             Partition distribution Version  \n",
       "0                No valid partition   3.6.0  \n",
       "1                No valid partition   3.6.0  \n",
       "2  rag_workshop:1, rag_workshop_1:1   3.6.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activate connections\n",
    "%ngql SHOW HOSTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = nl2kg_query_engine.query(\"SHOW HOSTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The Cypher Query is:\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "```cypher\n",
       "MATCH (e1:`entity`)-[r:`relationship`]->(e2:`entity`)\n",
       "WHERE e1.`entity`.`name` == 'Rocket'\n",
       "RETURN e2.`entity`.`name` AS Rocket\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n",
      "The Answer is:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Rocket is associated with several entities and relationships. Some of the entities related to Rocket include Adam Warlock, baby raccoon, Batch 89 test subjects, and a bounty hunter. Additionally, Rocket has relationships with friends, his past, and healing.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Tell me about Rocket?\n",
    "\"\"\"\n",
    "\n",
    "response_nl2kg = nl2kg_query_engine.query(question)\n",
    "\n",
    "# Cypher:\n",
    "\n",
    "print(\"The Cypher Query is:\")\n",
    "\n",
    "query_string = nl2kg_query_engine.generate_query(question)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "```cypher\n",
    "{query_string}\n",
    "```\n",
    "\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "%ngql {query_string}\n",
    "\n",
    "# Answer:\n",
    "\n",
    "print(\"The Answer is:\")\n",
    "\n",
    "display(Markdown(f\"<b>{response_nl2kg}</b>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The Cypher Query is:\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "```cypher\n",
       "MATCH (e1:`entity`)-[:relationship]->(e2:`entity`)\n",
       "WHERE e1.`name` == 'openai' AND e2.`name` == 'ceo'\n",
       "RETURN e2.`name`\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n",
      "The Answer is:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The CEO of OpenAI is not available in the given context information.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "who is openai's ceo?\n",
    "\"\"\"\n",
    "\n",
    "response_nl2kg = nl2kg_query_engine.query(question)\n",
    "\n",
    "# Cypher:\n",
    "\n",
    "print(\"The Cypher Query is:\")\n",
    "\n",
    "query_string = nl2kg_query_engine.generate_query(question)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "```cypher\n",
    "{query_string}\n",
    "```\n",
    "\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "%ngql {query_string}\n",
    "\n",
    "# Answer:\n",
    "\n",
    "print(\"The Answer is:\")\n",
    "\n",
    "display(Markdown(f\"<b>{response_nl2kg}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valina LLM + Prompts doesn't work well on all questions, fine-tuning, or few-shot ways could push further.\n",
    "\n",
    "But Graph RAG is easier as:\n",
    "\n",
    "The query-composing doesn't rely on the higher intelligence\n",
    "Easier to enable approximate starting entities\n",
    "Easier to push CoT-like task-break-down in the orchestration layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_index_query_engine = kg_index.as_query_engine(\n",
    "    retriever_mode=\"keyword\",\n",
    "    verbose=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mExtraced keywords: ['challenges', 'Rocket', 'Lylla']\n",
      "\u001B[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 44061e4b-533a-4790-b663-b0d6667169a3: The Guardians' med-packs are ineffective at healing Rocket's wounds, due to a...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 7c2eb7cd-2e79-49fc-b7a7-25cbf3a15efc: 3 fulfills a character arc for the character writer and director James Gunn e...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: b9215a6d-83a6-492c-abfb-c548ec34ea88: Arête departs as a spaceship, with Nebula, Drax, and Mantis boarding to rescu...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 98d4b832-8cfe-432d-896b-46be15adbf3a: === Post-production ===\n",
      "In early June 2022, Daniela Melchior was revealed to ...\n",
      "\u001B[36;1m\u001B[1;3mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Rocket, <-[reunites with]-, Lylla, <-[revealed to be voicing]-, Linda Cardellini\n",
      "Rocket, <-[accomplice of]-, Groot, <-[provided motion-capture for]-, Austin Freeman\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is created by]->, High Priestess Ayesha\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[seeks to destroy]->, Guardians of the Galaxy\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is stabbed by]->, Nebula\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[created]-, Sovereign\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[is]-, Chukwudi Iwuji\n",
      "Rocket, -[found as]->, baby raccoon\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[created to destroy]->, Guardians\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock\n",
      "Rocket, -[recalls]->, past\n",
      "Rocket, -[befriended]->, Batch 89 test subjects\n",
      "Rocket, -[former Avenger]->, bounty hunter\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[are attacked by]-, Guardians of the Galaxy\n",
      "Rocket, <-[experimented on]-, High Evolutionary\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[impressed by]->, Rocket's growing intelligence\n",
      "Rocket, -[attempted to free]->, friends\n",
      "Rocket, <-[accomplice of]-, Groot\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[sought to enhance]->, animal lifeforms\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[revealed to be portraying]-, Iwuji\n",
      "Rocket, <-[reunites with]-, Lylla\n",
      "Rocket, -[wounds]->, healing\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[was cast as]-, Poulter\n",
      "Lylla, -[reunites with]->, Rocket, -[former Avenger]->, bounty hunter\n",
      "Lylla, -[reunites with]->, Rocket, -[recalls]->, past\n",
      "Lylla, -[reunites with]->, Rocket, -[befriended]->, Batch 89 test subjects\n",
      "Lylla, -[reunites with]->, Rocket, -[attempted to free]->, friends\n",
      "Lylla, <-[revealed to be voicing]-, Linda Cardellini\n",
      "Lylla, -[reunites with]->, Rocket\n",
      "Lylla, -[reunites with]->, Rocket, -[found as]->, baby raccoon\n",
      "Lylla, -[reunites with]->, Rocket, <-[experimented on]-, High Evolutionary\n",
      "Lylla, -[reunites with]->, Rocket, <-[accomplice of]-, Groot\n",
      "Lylla, -[reunites with]->, Rocket, -[wounds]->, healing\n",
      "Lylla, -[reunites with]->, Rocket, -[is critically wounded by]->, Adam Warlock\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Rocket and Lylla face several challenges throughout their journey. They were both experimented on by the High Evolutionary, who sought to enhance and anthropomorphize animal lifeforms. Rocket attempted to free his friends, including Lylla, but they were ultimately killed by the High Evolutionary and his henchmen. Rocket himself was critically wounded by Adam Warlock, which posed a significant challenge to his survival. Additionally, Rocket and Lylla had to confront the emotional toll of their past experiences and the grief of losing their friends.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_graph_rag = kg_index_query_engine.query(\"What challenges do Rocket and Lylla face?\")\n",
    "\n",
    "display(Markdown(f\"<b>{response_graph_rag}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mExtraced keywords: ['James Gunn', 'James', 'Gunn']\n",
      "\u001B[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: a603a534-8d77-4510-a506-a130f3b5081c: By mid-October, James Gunn had completed his exit settlement with Disney and ...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 7c2eb7cd-2e79-49fc-b7a7-25cbf3a15efc: 3 fulfills a character arc for the character writer and director James Gunn e...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: affacc55-8018-4023-8f7b-1989ebfac93b: Iwuji was also announced as playing the High Evolutionary, appearing at the p...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 9693d254-2796-45b7-8c7e-e10c57ad729f: In April 2016, Marvel Studios president Kevin Feige, the producer of the Guar...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 9034cbdd-5713-496c-8737-6fb1d07e5896: \"A negative review from NPR criticized the approach of cruelty to animals in ...\n",
      "\u001B[36;1m\u001B[1;3mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "James Gunn, -[set to write]->, The Suicide Squad, <-[joined]-, James Gunn\n",
      "James Gunn, -[set to write]->, The Suicide Squad, <-[potentially direct]-, James Gunn\n",
      "James Gunn, -[potentially direct]->, The Suicide Squad, <-[set to write]-, James Gunn\n",
      "James Gunn, -[potentially direct]->, The Suicide Squad, <-[joined]-, James Gunn\n",
      "James Gunn, -[envisioned]->, character arc, <-[continued]-, Guardians of the Galaxy Vol.2 (2017)\n",
      "James Gunn, -[joined]->, The Suicide Squad, <-[potentially direct]-, James Gunn\n",
      "James Gunn, -[joined]->, The Suicide Squad\n",
      "James Gunn, -[completed]->, exit settlement\n",
      "James Gunn, <-[writer and director]-, character, <-[provided motion capture for]-, Sean Gunn\n",
      "James Gunn, -[potentially direct]->, The Suicide Squad\n",
      "James Gunn, -[envisioned]->, character arc\n",
      "James Gunn, -[joined]->, The Suicide Squad, <-[starred in]-, Daniela Melchior\n",
      "James Gunn, -[potentially direct]->, The Suicide Squad, <-[starred in]-, Daniela Melchior\n",
      "James Gunn, <-[writer and director]-, character\n",
      "James Gunn, -[envisioned]->, character arc, <-[continued]-, Infinity War\n",
      "James Gunn, <-[starting work on]-, Guardians of the Galaxy (2014)\n",
      "James Gunn, -[set to write]->, The Suicide Squad, <-[starred in]-, Daniela Melchior\n",
      "James Gunn, -[set to write]->, The Suicide Squad\n",
      "James Gunn, -[envisioned]->, character arc, <-[established]-, Guardians of the Galaxy\n",
      "James Gunn, -[joined]->, The Suicide Squad, <-[set to write]-, James Gunn\n",
      "James Gunn, -[notified]->, he could return as director\n",
      "James Gunn, -[envisioned]->, character arc, <-[fulfills]-, 3\n",
      "James Gunn, -[envisioned]->, character arc, <-[continued]-, Endgame\n",
      "Gunn, <-[gave]-, People for the Ethical Treatment of Animals (PETA), -[gave]->, Not a Number Award\n",
      "Gunn, <-[gave]-, People for the Ethical Treatment of Animals (PETA), -[declared]->, best animal rights film of the year\n",
      "Gunn, -[narrowed down]->, choices, <-[had to make]-, Gunn\n",
      "Gunn, -[received]->, Not a Number Award, <-[gave]-, People for the Ethical Treatment of Animals (PETA)\n",
      "Gunn, -[signed on to]->, film, -[on]->, A+ to F scale\n",
      "Gunn, -[signed on to]->, film, -[have a heavier story than]->, previous films\n",
      "Gunn, -[signed on to]->, film, -[average grade of]->, A\n",
      "Gunn, -[signed on to]->, film, -[teases]->, possible romance\n",
      "Gunn, -[signed on to]->, film, <-[promote]-, Microsoft\n",
      "Gunn, -[signed on to]->, film, -[positive score]->, 91%\n",
      "Gunn, -[signed on to]->, film, <-[gave]-, moviegoers\n",
      "Gunn, -[met with]->, Horn, -[changed his mind]->, impressed by Gunn's response\n",
      "Gunn, -[eventually returning]->, in some capacity\n",
      "Gunn, -[felt]->, music\n",
      "Gunn, -[asked]->, unhappy about Marvel's decision to kill Gamora\n",
      "Gunn, -[signed on to]->, film, -[saying]->, they would definitely recommend it\n",
      "Gunn, -[met with]->, Horn\n",
      "Gunn, -[did not breach]->, contract\n",
      "Gunn, -[stated]->, the film would be shot using Industrial Light & Magic's StageCraft virtual production technology\n",
      "Gunn, -[had to make]->, choices, <-[narrowed down]-, Gunn\n",
      "Gunn, -[said]->, dozens of roles  had already been cast\n",
      "Gunn, -[signed on to]->, film, -[ends with]->, Dog Days Are Over\n",
      "Gunn, -[said]->, he would be creating the third film\n",
      "Gunn, -[wanted]->, somebody who was youthful\n",
      "Gunn, -[added]->, panicking\n",
      "Gunn, -[failed efforts to be]->, provocative\n",
      "Gunn, -[reiterated]->, his comments on not resurrecting Yondu\n",
      "Gunn, -[said]->, wouldn't have said yes\n",
      "Gunn, -[had in mind]->, Fantastic Four villain Annihilus\n",
      "Gunn, -[received]->, Not a Number Award\n",
      "Gunn, -[stated]->, the footage was not released publicly\n",
      "Gunn, -[planned to work with]->, Marvel on the future\n",
      "Gunn, -[depicted]->, animal testing\n",
      "Gunn, -[unable to use]->, song\n",
      "Gunn, -[said]->, they would not be able to use the technology because the sets were too big\n",
      "Gunn, -[planned to meet with]->, Mark Hamill about possibly appearing in the film\n",
      "Gunn, -[was considering changing]->, a piece of character info he had placed in the background of the mugshot sequence\n",
      "Gunn, -[narrowed down]->, choices\n",
      "Gunn, -[signed on to]->, film\n",
      "Gunn, -[publicly revealed]->, rehired as director\n",
      "Gunn, -[discussed]->, storyline with studio beforehand\n",
      "Gunn, -[signed on to]->, film, <-[found]-, Independent\n",
      "Gunn, -[signed on to]->, film, <-[gave]-, CinemaScore\n",
      "Gunn, -[tells]->, Rocket's story\n",
      "Gunn, -[discussed]->, commitments to The Suicide Squad\n",
      "Gunn, -[confirmed]->, Pom Klementieff would reprise her role as Mantis\n",
      "Gunn, -[said]->, tweets\n",
      "Gunn, -[had to make]->, choices\n",
      "Gunn, -[posted]->, a photo of the main cast members\n",
      "Gunn, -[said]->, tweets, -[were written]->, years before\n",
      "Gunn, -[thought]->, Warlock's interactions\n",
      "Gunn, -[noted]->, list could grow\n",
      "Gunn, -[had completed]->, the first draft of his script treatment for the third film\n",
      "Gunn, -[understand and accept]->, business decisions\n",
      "Gunn, -[signed on to]->, film, <-[found]-, Vox\n",
      "Gunn, -[begun storyboarding]->, June\n",
      "Gunn, <-[severed ties with]-, Disney and Marvel\n",
      "Gunn, -[signed on to]->, film, <-[gave]-, Audiences\n",
      "Gunn, -[be free to move on to]->, new projects\n",
      "Gunn, -[meeting with]->, actors for the role of Adam Warlock\n",
      "Gunn, -[signed on to]->, film, <-[promote]-, Marvel Studios\n",
      "Gunn, -[used for]->, soundtracks\n",
      "Gunn, -[signed on to]->, film, -[opens with]->, version of  Creep\n",
      "Gunn, -[intended to have]->, Elizabeth Debicki reprise her role as Ayesha\n",
      "Gunn, -[announced]->, return to write and direct\n",
      "Gunn, <-[gave]-, People for the Ethical Treatment of Animals (PETA)\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>James Gunn is a writer and director who has worked on several films, including the Guardians of the Galaxy franchise. He was initially set to write and potentially direct The Suicide Squad for Warner Bros / DC Films. However, he was later notified that he could return as the director for Guardians of the Galaxy Vol. 3. Gunn has a clear vision for the character arcs in the Guardians films and has been involved in the development of the Marvel Cosmic Universe. He has also received accolades for his work, including a Not a Number Award from People for the Ethical Treatment of Animals (PETA) for his depiction of animal testing in one of his films. Gunn has been praised for his storytelling and the emotional depth of his films.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response_graph_rag = kg_index_query_engine.query(\"Tell me about James Gunn.\")\n",
    "\n",
    "display(Markdown(f\"<b>{response_graph_rag}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>(\"Gunn\" :entity{name: \"Gunn\"})-[:relationship@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>(\"Gunn\" :entity{name: \"Gunn\"})-[:relationship@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>(\"Gunn\" :entity{name: \"Gunn\"})-[:relationship@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(\"Gunn\" :entity{name: \"Gunn\"})&lt;-[:relationship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>(\"Gunn\" :entity{name: \"Gunn\"})&lt;-[:relationship...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    p\n",
       "0   (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "1   (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "2   (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "3   (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "4   (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "..                                                ...\n",
       "84  (\"Gunn\" :entity{name: \"Gunn\"})-[:relationship@...\n",
       "85  (\"Gunn\" :entity{name: \"Gunn\"})-[:relationship@...\n",
       "86  (\"Gunn\" :entity{name: \"Gunn\"})-[:relationship@...\n",
       "87  (\"Gunn\" :entity{name: \"Gunn\"})<-[:relationship...\n",
       "88  (\"Gunn\" :entity{name: \"Gunn\"})<-[:relationship...\n",
       "\n",
       "[89 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ngql USE rag_workshop_1; MATCH p=(n)-[e:relationship*1..2]-() WHERE id(n) in ['James Gunn', 'James', 'Gunn'] RETURN p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "The Cypher Query is:\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "```cypher\n",
       "MATCH (e1:`entity`)-[r:`relationship`]->(e2:`entity`)\n",
       "WHERE e1.`entity`.`name` == 'James Gunn'\n",
       "RETURN e2.`entity`.`name`\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n",
      "The Answer is:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>James Gunn is associated with various entities and relationships, including \"exit settlement,\" \"character arc,\" and \"The Suicide Squad.\" Additionally, there is mention of the possibility of him returning as a director.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Tell me about James Gunn.\n",
    "\"\"\"\n",
    "\n",
    "response_nl2kg = nl2kg_query_engine.query(question)\n",
    "\n",
    "# Cypher:\n",
    "\n",
    "print(\"The Cypher Query is:\")\n",
    "\n",
    "query_string = nl2kg_query_engine.generate_query(question)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "```cypher\n",
    "{query_string}\n",
    "```\n",
    "\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "%ngql {query_string}\n",
    "\n",
    "# Answer:\n",
    "\n",
    "print(\"The Answer is:\")\n",
    "\n",
    "display(Markdown(f\"<b>{response_nl2kg}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('192.168.64.1', 9669)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   p\n",
       "0  (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "1  (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "2  (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "3  (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "4  (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r...\n",
       "5  (\"James Gunn\" :entity{name: \"James Gunn\"})-[:r..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ngql\n",
    "MATCH p=(e1:`entity`)-[r:`relationship`]->(e2:`entity`)\n",
    "WHERE e1.`entity`.`name` == 'James Gunn'\n",
    "RETURN p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ng_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mExtraced keywords: ['Rocket']\n",
      "\u001B[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: b9215a6d-83a6-492c-abfb-c548ec34ea88: Arête departs as a spaceship, with Nebula, Drax, and Mantis boarding to rescu...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 8c9a0848-de88-41ed-a40a-45f54983ec54: Guardians of the Galaxy Vol. 3 (stylized in marketing as Guardians of the Gal...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 44061e4b-533a-4790-b663-b0d6667169a3: The Guardians' med-packs are ineffective at healing Rocket's wounds, due to a...\n",
      "\u001B[36;1m\u001B[1;3mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Rocket, <-[reunites with]-, Lylla, <-[revealed to be voicing]-, Linda Cardellini\n",
      "Rocket, <-[accomplice of]-, Groot, <-[provided motion-capture for]-, Austin Freeman\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is created by]->, High Priestess Ayesha\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[seeks to destroy]->, Guardians of the Galaxy\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is stabbed by]->, Nebula\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[created]-, Sovereign\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[is]-, Chukwudi Iwuji\n",
      "Rocket, -[found as]->, baby raccoon\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[created to destroy]->, Guardians\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock\n",
      "Rocket, -[recalls]->, past\n",
      "Rocket, -[befriended]->, Batch 89 test subjects\n",
      "Rocket, -[former Avenger]->, bounty hunter\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[are attacked by]-, Guardians of the Galaxy\n",
      "Rocket, <-[experimented on]-, High Evolutionary\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[impressed by]->, Rocket's growing intelligence\n",
      "Rocket, -[attempted to free]->, friends\n",
      "Rocket, <-[accomplice of]-, Groot\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[sought to enhance]->, animal lifeforms\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[revealed to be portraying]-, Iwuji\n",
      "Rocket, <-[reunites with]-, Lylla\n",
      "Rocket, -[wounds]->, healing\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[was cast as]-, Poulter\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Rocket is a fictional character in the Marvel Comics and the Marvel Cinematic Universe. He is a genetically modified raccoon and a member of the superhero team Guardians of the Galaxy. Rocket is known for his expertise in weapons and tactics, as well as his sarcastic and witty personality. He is voiced by Bradley Cooper in the MCU films.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mExtraced keywords: ['Lylla']\n",
      "\u001B[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: b9215a6d-83a6-492c-abfb-c548ec34ea88: Arête departs as a spaceship, with Nebula, Drax, and Mantis boarding to rescu...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 98d4b832-8cfe-432d-896b-46be15adbf3a: === Post-production ===\n",
      "In early June 2022, Daniela Melchior was revealed to ...\n",
      "\u001B[36;1m\u001B[1;3mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Lylla, -[reunites with]->, Rocket, -[former Avenger]->, bounty hunter\n",
      "Lylla, -[reunites with]->, Rocket, -[recalls]->, past\n",
      "Lylla, -[reunites with]->, Rocket, -[befriended]->, Batch 89 test subjects\n",
      "Lylla, -[reunites with]->, Rocket, -[attempted to free]->, friends\n",
      "Lylla, <-[revealed to be voicing]-, Linda Cardellini\n",
      "Lylla, -[reunites with]->, Rocket\n",
      "Lylla, -[reunites with]->, Rocket, -[found as]->, baby raccoon\n",
      "Lylla, -[reunites with]->, Rocket, <-[experimented on]-, High Evolutionary\n",
      "Lylla, -[reunites with]->, Rocket, <-[accomplice of]-, Groot\n",
      "Lylla, -[reunites with]->, Rocket, -[wounds]->, healing\n",
      "Lylla, -[reunites with]->, Rocket, -[is critically wounded by]->, Adam Warlock\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m response \u001B[38;5;241m=\u001B[39m chat_engine\u001B[38;5;241m.\u001B[39mchat(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwho is Rocket?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     10\u001B[0m display(Markdown(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<b>\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m</b>\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m---> 12\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mchat_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwho is Lylla?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m display(Markdown(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<b>\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m</b>\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# response = chat_engine.chat(\"who is Groot?\")\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# display(Markdown(f\"<b>{response}</b>\"))\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# response = chat_engine.chat(\"do they all know each other?\")\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# display(Markdown(f\"<b>{response}</b>\"))\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/callbacks/utils.py:38\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m callback_manager \u001B[38;5;241m=\u001B[39m cast(CallbackManager, callback_manager)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m callback_manager\u001B[38;5;241m.\u001B[39mas_trace(trace_id):\n\u001B[0;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/chat_engine/context.py:150\u001B[0m, in \u001B[0;36mContextChatEngine.chat\u001B[0;34m(self, message, chat_history)\u001B[0m\n\u001B[1;32m    147\u001B[0m prefix_messages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_prefix_messages_with_context(context_str_template)\n\u001B[1;32m    148\u001B[0m all_messages \u001B[38;5;241m=\u001B[39m prefix_messages \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory\u001B[38;5;241m.\u001B[39mget()\n\u001B[0;32m--> 150\u001B[0m chat_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_llm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_messages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m ai_message \u001B[38;5;241m=\u001B[39m chat_response\u001B[38;5;241m.\u001B[39mmessage\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory\u001B[38;5;241m.\u001B[39mput(ai_message)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/base.py:143\u001B[0m, in \u001B[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001B[0;34m(_self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m wrapper_logic(_self) \u001B[38;5;28;01mas\u001B[39;00m callback_manager:\n\u001B[1;32m    140\u001B[0m     event_id \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_event_start(\n\u001B[1;32m    141\u001B[0m         CBEventType\u001B[38;5;241m.\u001B[39mLLM, payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mMESSAGES: messages}\n\u001B[1;32m    142\u001B[0m     )\n\u001B[0;32m--> 143\u001B[0m     f_return_val \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_self\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f_return_val, Generator):\n\u001B[1;32m    146\u001B[0m         \u001B[38;5;66;03m# intercept the generator and add a callback to the end\u001B[39;00m\n\u001B[1;32m    147\u001B[0m         \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_gen\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatResponseGen:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/openai.py:111\u001B[0m, in \u001B[0;36mOpenAI.chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    110\u001B[0m     chat_fn \u001B[38;5;241m=\u001B[39m completion_to_chat_decorator(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_complete)\n\u001B[0;32m--> 111\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mchat_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/openai.py:168\u001B[0m, in \u001B[0;36mOpenAI._chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m message_dicts \u001B[38;5;241m=\u001B[39m to_openai_message_dicts(messages)\n\u001B[1;32m    167\u001B[0m all_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_all_kwargs(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 168\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mcompletion_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_chat_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_is_chat_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessage_dicts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mall_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;66;03m# print(response)\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;66;03m# response \u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;66;03m# \"\"\"\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    180\u001B[0m \n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# message_dict = response[\"choices\"][0][\"message\"]\u001B[39;00m\n\u001B[1;32m    182\u001B[0m ChatCompletionMessage \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/openai_utils.py:142\u001B[0m, in \u001B[0;36mcompletion_with_retry\u001B[0;34m(is_chat_model, max_retries, **kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m     client \u001B[38;5;241m=\u001B[39m get_completion_endpoint(is_chat_model)\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_completion_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:389\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoSleep):\n\u001B[1;32m    388\u001B[0m     retry_state\u001B[38;5;241m.\u001B[39mprepare_for_next_attempt()\n\u001B[0;32m--> 389\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m do\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/nap.py:31\u001B[0m, in \u001B[0;36msleep\u001B[0;34m(seconds)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msleep\u001B[39m(seconds: \u001B[38;5;28mfloat\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     26\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseconds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from llama_index.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
    "\n",
    "chat_engine = kg_index.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    verbose=True\n",
    ")\n",
    "response = chat_engine.chat(\"who is Rocket?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))\n",
    "\n",
    "response = chat_engine.chat(\"who is Lylla?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))\n",
    "\n",
    "# response = chat_engine.chat(\"who is Groot?\")\n",
    "# display(Markdown(f\"<b>{response}</b>\"))\n",
    "\n",
    "# response = chat_engine.chat(\"do they all know each other?\")\n",
    "# display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mExtraced keywords: ['Lylla']\n",
      "\u001B[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: b9215a6d-83a6-492c-abfb-c548ec34ea88: Arête departs as a spaceship, with Nebula, Drax, and Mantis boarding to rescu...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 98d4b832-8cfe-432d-896b-46be15adbf3a: === Post-production ===\n",
      "In early June 2022, Daniela Melchior was revealed to ...\n",
      "\u001B[36;1m\u001B[1;3mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Lylla, -[reunites with]->, Rocket, -[former Avenger]->, bounty hunter\n",
      "Lylla, -[reunites with]->, Rocket, -[recalls]->, past\n",
      "Lylla, -[reunites with]->, Rocket, -[befriended]->, Batch 89 test subjects\n",
      "Lylla, -[reunites with]->, Rocket, -[attempted to free]->, friends\n",
      "Lylla, <-[revealed to be voicing]-, Linda Cardellini\n",
      "Lylla, -[reunites with]->, Rocket\n",
      "Lylla, -[reunites with]->, Rocket, -[found as]->, baby raccoon\n",
      "Lylla, -[reunites with]->, Rocket, <-[experimented on]-, High Evolutionary\n",
      "Lylla, -[reunites with]->, Rocket, <-[accomplice of]-, Groot\n",
      "Lylla, -[reunites with]->, Rocket, -[wounds]->, healing\n",
      "Lylla, -[reunites with]->, Rocket, -[is critically wounded by]->, Adam Warlock\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n",
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 400 Bad Request\"\n",
      "WARNING:llama_index.llms.openai_utils:Retrying llama_index.llms.openai_utils.completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised BadRequestError: Error code: 400 - {'error': {'message': \"None is not of type 'object' - 'messages.2.function_call'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mchat_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBut how about Lylla?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m display(Markdown(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<b>\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresponse\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m</b>\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/callbacks/utils.py:38\u001B[0m, in \u001B[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m callback_manager \u001B[38;5;241m=\u001B[39m cast(CallbackManager, callback_manager)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m callback_manager\u001B[38;5;241m.\u001B[39mas_trace(trace_id):\n\u001B[0;32m---> 38\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/chat_engine/context.py:150\u001B[0m, in \u001B[0;36mContextChatEngine.chat\u001B[0;34m(self, message, chat_history)\u001B[0m\n\u001B[1;32m    147\u001B[0m prefix_messages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_prefix_messages_with_context(context_str_template)\n\u001B[1;32m    148\u001B[0m all_messages \u001B[38;5;241m=\u001B[39m prefix_messages \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory\u001B[38;5;241m.\u001B[39mget()\n\u001B[0;32m--> 150\u001B[0m chat_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_llm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mall_messages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m ai_message \u001B[38;5;241m=\u001B[39m chat_response\u001B[38;5;241m.\u001B[39mmessage\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_memory\u001B[38;5;241m.\u001B[39mput(ai_message)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/base.py:143\u001B[0m, in \u001B[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001B[0;34m(_self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m wrapper_logic(_self) \u001B[38;5;28;01mas\u001B[39;00m callback_manager:\n\u001B[1;32m    140\u001B[0m     event_id \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_event_start(\n\u001B[1;32m    141\u001B[0m         CBEventType\u001B[38;5;241m.\u001B[39mLLM, payload\u001B[38;5;241m=\u001B[39m{EventPayload\u001B[38;5;241m.\u001B[39mMESSAGES: messages}\n\u001B[1;32m    142\u001B[0m     )\n\u001B[0;32m--> 143\u001B[0m     f_return_val \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_self\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(f_return_val, Generator):\n\u001B[1;32m    146\u001B[0m         \u001B[38;5;66;03m# intercept the generator and add a callback to the end\u001B[39;00m\n\u001B[1;32m    147\u001B[0m         \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_gen\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ChatResponseGen:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/openai.py:111\u001B[0m, in \u001B[0;36mOpenAI.chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    110\u001B[0m     chat_fn \u001B[38;5;241m=\u001B[39m completion_to_chat_decorator(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_complete)\n\u001B[0;32m--> 111\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mchat_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/openai.py:168\u001B[0m, in \u001B[0;36mOpenAI._chat\u001B[0;34m(self, messages, **kwargs)\u001B[0m\n\u001B[1;32m    166\u001B[0m message_dicts \u001B[38;5;241m=\u001B[39m to_openai_message_dicts(messages)\n\u001B[1;32m    167\u001B[0m all_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_all_kwargs(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 168\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mcompletion_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_chat_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_is_chat_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmessage_dicts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mall_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;66;03m# print(response)\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;66;03m# response \u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;66;03m# \"\"\"\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    180\u001B[0m \n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# message_dict = response[\"choices\"][0][\"message\"]\u001B[39;00m\n\u001B[1;32m    182\u001B[0m ChatCompletionMessage \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mchoices[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/llms/openai_utils.py:142\u001B[0m, in \u001B[0;36mcompletion_with_retry\u001B[0;34m(is_chat_model, max_retries, **kwargs)\u001B[0m\n\u001B[1;32m    139\u001B[0m     client \u001B[38;5;241m=\u001B[39m get_completion_endpoint(is_chat_model)\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 142\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_completion_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:389\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoSleep):\n\u001B[1;32m    388\u001B[0m     retry_state\u001B[38;5;241m.\u001B[39mprepare_for_next_attempt()\n\u001B[0;32m--> 389\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m do\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/nap.py:31\u001B[0m, in \u001B[0;36msleep\u001B[0;34m(seconds)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msleep\u001B[39m(seconds: \u001B[38;5;28mfloat\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     26\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseconds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "response = chat_engine.chat(\"But how about Lylla?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[38;5;200m\u001B[1;3mThought: I can use the query_engine_tool to find information about Rocket.\n",
      "Action: query_engine_tool\n",
      "Action Input: {'input': 'Who is Rocket?'}\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mExtraced keywords: ['Rocket']\n",
      "\u001B[0mWARNING:llama_index.indices.knowledge_graph.retrievers:Index was not constructed with embeddings, skipping embedding usage...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: b9215a6d-83a6-492c-abfb-c548ec34ea88: Arête departs as a spaceship, with Nebula, Drax, and Mantis boarding to rescu...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 8c9a0848-de88-41ed-a40a-45f54983ec54: Guardians of the Galaxy Vol. 3 (stylized in marketing as Guardians of the Gal...\n",
      "INFO:llama_index.indices.knowledge_graph.retrievers:> Querying with idx: 44061e4b-533a-4790-b663-b0d6667169a3: The Guardians' med-packs are ineffective at healing Rocket's wounds, due to a...\n",
      "\u001B[36;1m\u001B[1;3mKG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...`\n",
      "Rocket, <-[reunites with]-, Lylla, <-[revealed to be voicing]-, Linda Cardellini\n",
      "Rocket, <-[accomplice of]-, Groot, <-[provided motion-capture for]-, Austin Freeman\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is created by]->, High Priestess Ayesha\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[seeks to destroy]->, Guardians of the Galaxy\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is stabbed by]->, Nebula\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[created]-, Sovereign\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[is]-, Chukwudi Iwuji\n",
      "Rocket, -[found as]->, baby raccoon\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[created to destroy]->, Guardians\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock\n",
      "Rocket, -[recalls]->, past\n",
      "Rocket, -[befriended]->, Batch 89 test subjects\n",
      "Rocket, -[former Avenger]->, bounty hunter\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[are attacked by]-, Guardians of the Galaxy\n",
      "Rocket, <-[experimented on]-, High Evolutionary\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[impressed by]->, Rocket's growing intelligence\n",
      "Rocket, -[attempted to free]->, friends\n",
      "Rocket, <-[accomplice of]-, Groot\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[sought to enhance]->, animal lifeforms\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[revealed to be portraying]-, Iwuji\n",
      "Rocket, <-[reunites with]-, Lylla\n",
      "Rocket, -[wounds]->, healing\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[was cast as]-, Poulter\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[36;1m\u001B[1;3mObservation: Rocket is a character who is a member of the Guardians of the Galaxy. He is a former Avenger and a bounty hunter. Rocket was found as a baby raccoon and was experimented on by the High Evolutionary, the leader of Orgocorp. He befriended his fellow test subjects, including the otter Lylla, the walrus Teefs, and the rabbit Floor. Rocket has a critical role in the plot, as he is critically wounded by Adam Warlock and the Guardians must find a way to save his life.\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[38;5;200m\u001B[1;3mResponse: Rocket is a character who is a member of the Guardians of the Galaxy. He is a former Avenger and a bounty hunter. Rocket was found as a baby raccoon and was experimented on by the High Evolutionary, the leader of Orgocorp. He befriended his fellow test subjects, including the otter Lylla, the walrus Teefs, and the rabbit Floor. Rocket has a critical role in the plot, as he is critically wounded by Adam Warlock and the Guardians must find a way to save his life.\n",
      "\u001B[0m"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Rocket is a character who is a member of the Guardians of the Galaxy. He is a former Avenger and a bounty hunter. Rocket was found as a baby raccoon and was experimented on by the High Evolutionary, the leader of Orgocorp. He befriended his fellow test subjects, including the otter Lylla, the walrus Teefs, and the rabbit Floor. Rocket has a critical role in the plot, as he is critically wounded by Adam Warlock and the Guardians must find a way to save his life.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
    "\n",
    "chat_engine = kg_index.as_chat_engine(\n",
    "    chat_mode=\"react\",\n",
    "    verbose=True\n",
    ")\n",
    "response = chat_engine.chat(\"who is Rocket?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_rag_retriever_with_nl2graphquery = KnowledgeGraphRAGRetriever(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=lc_llm,\n",
    "    verbose=True,\n",
    "    with_nl2graphquery=True,\n",
    ")\n",
    "\n",
    "query_engine_with_nl2graphquery = RetrieverQueryEngine.from_args(\n",
    "    graph_rag_retriever_with_nl2graphquery, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.retrievers import KnowledgeGraphRAGRetriever\n",
    "\n",
    "graph_rag_retriever = KnowledgeGraphRAGRetriever(\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    graph_rag_retriever, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mEntities processed: ['Rocket']\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001B[32;1m\u001B[1;3mEntities processed: ['rockets', 'rocket']\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3mGraph RAG context:\n",
      "The following are knowledge sequence in max depth 2 in the form of directed graph like:\n",
      "`subject -[predicate]->, object, <-[predicate_next_hop]-, object_next_hop ...` extracted based on key entities as subject:\n",
      "Rocket, <-[reunites with]-, Lylla, <-[revealed to be voicing]-, Linda Cardellini\n",
      "Rocket, <-[accomplice of]-, Groot, <-[provided motion-capture for]-, Austin Freeman\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is created by]->, High Priestess Ayesha\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[seeks to destroy]->, Guardians of the Galaxy\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[is stabbed by]->, Nebula\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[created]-, Sovereign\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[is]-, Chukwudi Iwuji\n",
      "Rocket, -[found as]->, baby raccoon\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, -[created to destroy]->, Guardians\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock\n",
      "Rocket, -[recalls]->, past\n",
      "Rocket, -[befriended]->, Batch 89 test subjects\n",
      "Rocket, -[former Avenger]->, bounty hunter\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[are attacked by]-, Guardians of the Galaxy\n",
      "Rocket, <-[experimented on]-, High Evolutionary\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[impressed by]->, Rocket's growing intelligence\n",
      "Rocket, -[attempted to free]->, friends\n",
      "Rocket, <-[accomplice of]-, Groot\n",
      "Rocket, <-[experimented on]-, High Evolutionary, -[sought to enhance]->, animal lifeforms\n",
      "Rocket, <-[experimented on]-, High Evolutionary, <-[revealed to be portraying]-, Iwuji\n",
      "Rocket, <-[reunites with]-, Lylla\n",
      "Rocket, -[wounds]->, healing\n",
      "Rocket, -[is critically wounded by]->, Adam Warlock, <-[was cast as]-, Poulter\n",
      "\u001B[0mINFO:httpx:HTTP Request: POST https://aigptx.top/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>Rocket is a character who has been through various experiences, including being experimented on, reuniting with Lylla, being critically wounded by Adam Warlock, and being an accomplice of Groot.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is Rocket?\",\n",
    ")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7f8cea057bb0 state=finished raised APIRemovedInV1>]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAPIRemovedInV1\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:382\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 382\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/embeddings/openai.py:172\u001B[0m, in \u001B[0;36mget_embeddings\u001B[0;34m(list_of_text, engine, **kwargs)\u001B[0m\n\u001B[1;32m    170\u001B[0m list_of_text \u001B[38;5;241m=\u001B[39m [text\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m list_of_text]\n\u001B[0;32m--> 172\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbedding\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlist_of_text\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [d[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m data]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/lib/_old_api.py:39\u001B[0m, in \u001B[0;36mAPIRemovedInV1Proxy.__call__\u001B[0;34m(self, *_args, **_kwargs)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m_args: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_kwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m---> 39\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m APIRemovedInV1(symbol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_symbol)\n",
      "\u001B[0;31mAPIRemovedInV1\u001B[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRetryError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m vector_index \u001B[38;5;241m=\u001B[39m \u001B[43mVectorStoreIndex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mservice_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mservice_context\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/indices/base.py:102\u001B[0m, in \u001B[0;36mBaseIndex.from_documents\u001B[0;34m(cls, documents, storage_context, service_context, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m     97\u001B[0m     docstore\u001B[38;5;241m.\u001B[39mset_document_hash(doc\u001B[38;5;241m.\u001B[39mget_doc_id(), doc\u001B[38;5;241m.\u001B[39mhash)\n\u001B[1;32m     98\u001B[0m nodes \u001B[38;5;241m=\u001B[39m service_context\u001B[38;5;241m.\u001B[39mnode_parser\u001B[38;5;241m.\u001B[39mget_nodes_from_documents(\n\u001B[1;32m     99\u001B[0m     documents, show_progress\u001B[38;5;241m=\u001B[39mshow_progress\n\u001B[1;32m    100\u001B[0m )\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mservice_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mservice_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:46\u001B[0m, in \u001B[0;36mVectorStoreIndex.__init__\u001B[0;34m(self, nodes, index_struct, service_context, storage_context, use_async, store_nodes_override, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_async \u001B[38;5;241m=\u001B[39m use_async\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store_nodes_override \u001B[38;5;241m=\u001B[39m store_nodes_override\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_struct\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_struct\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mservice_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mservice_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/indices/base.py:71\u001B[0m, in \u001B[0;36mBaseIndex.__init__\u001B[0;34m(self, nodes, index_struct, storage_context, service_context, show_progress, **kwargs)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index_struct \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m nodes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m     index_struct \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_index_from_nodes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_struct \u001B[38;5;241m=\u001B[39m index_struct\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_storage_context\u001B[38;5;241m.\u001B[39mindex_store\u001B[38;5;241m.\u001B[39madd_index_struct(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_struct)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:241\u001B[0m, in \u001B[0;36mVectorStoreIndex.build_index_from_nodes\u001B[0;34m(self, nodes)\u001B[0m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild_index_from_nodes\u001B[39m(\u001B[38;5;28mself\u001B[39m, nodes: Sequence[BaseNode]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m IndexDict:\n\u001B[1;32m    235\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Build the index from nodes.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m \n\u001B[1;32m    237\u001B[0m \u001B[38;5;124;03m    NOTE: Overrides BaseIndex.build_index_from_nodes.\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;124;03m        VectorStoreIndex only stores nodes in document store\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;124;03m        if vector store does not store text\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_index_from_nodes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:229\u001B[0m, in \u001B[0;36mVectorStoreIndex._build_index_from_nodes\u001B[0;34m(self, nodes)\u001B[0m\n\u001B[1;32m    227\u001B[0m     run_async_tasks(tasks)\n\u001B[1;32m    228\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 229\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_add_nodes_to_index\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_struct\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_show_progress\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m index_struct\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:201\u001B[0m, in \u001B[0;36mVectorStoreIndex._add_nodes_to_index\u001B[0;34m(self, index_struct, nodes, show_progress)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m nodes:\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m--> 201\u001B[0m embedding_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_node_embedding_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m new_ids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vector_store\u001B[38;5;241m.\u001B[39madd(embedding_results)\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vector_store\u001B[38;5;241m.\u001B[39mstores_text \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_store_nodes_override:\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;66;03m# NOTE: if the vector store doesn't store text,\u001B[39;00m\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;66;03m# we need to add the nodes to the index struct and document store\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/indices/vector_store/base.py:111\u001B[0m, in \u001B[0;36mVectorStoreIndex._get_node_embedding_results\u001B[0;34m(self, nodes, show_progress)\u001B[0m\n\u001B[1;32m    105\u001B[0m         id_to_embed_map[n\u001B[38;5;241m.\u001B[39mnode_id] \u001B[38;5;241m=\u001B[39m n\u001B[38;5;241m.\u001B[39membedding\n\u001B[1;32m    107\u001B[0m \u001B[38;5;66;03m# call embedding model to get embeddings\u001B[39;00m\n\u001B[1;32m    108\u001B[0m (\n\u001B[1;32m    109\u001B[0m     result_ids,\n\u001B[1;32m    110\u001B[0m     result_embeddings,\n\u001B[0;32m--> 111\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_service_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_queued_text_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mshow_progress\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m new_id, text_embedding \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(result_ids, result_embeddings):\n\u001B[1;32m    113\u001B[0m     id_to_embed_map[new_id] \u001B[38;5;241m=\u001B[39m text_embedding\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/embeddings/base.py:217\u001B[0m, in \u001B[0;36mBaseEmbedding.get_queued_text_embeddings\u001B[0;34m(self, show_progress)\u001B[0m\n\u001B[1;32m    215\u001B[0m cur_batch_ids \u001B[38;5;241m=\u001B[39m [text_id \u001B[38;5;28;01mfor\u001B[39;00m text_id, _ \u001B[38;5;129;01min\u001B[39;00m cur_batch]\n\u001B[1;32m    216\u001B[0m cur_batch_texts \u001B[38;5;241m=\u001B[39m [text \u001B[38;5;28;01mfor\u001B[39;00m _, text \u001B[38;5;129;01min\u001B[39;00m cur_batch]\n\u001B[0;32m--> 217\u001B[0m embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_text_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcur_batch_texts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m result_ids\u001B[38;5;241m.\u001B[39mextend(cur_batch_ids)\n\u001B[1;32m    219\u001B[0m result_embeddings\u001B[38;5;241m.\u001B[39mextend(embeddings)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/llama_index/embeddings/openai.py:318\u001B[0m, in \u001B[0;36mOpenAIEmbedding._get_text_embeddings\u001B[0;34m(self, texts)\u001B[0m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_text_embeddings\u001B[39m(\u001B[38;5;28mself\u001B[39m, texts: List[\u001B[38;5;28mstr\u001B[39m]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[List[\u001B[38;5;28mfloat\u001B[39m]]:\n\u001B[1;32m    312\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get text embeddings.\u001B[39;00m\n\u001B[1;32m    313\u001B[0m \n\u001B[1;32m    314\u001B[0m \u001B[38;5;124;03m    By default, this is a wrapper around _get_text_embedding.\u001B[39;00m\n\u001B[1;32m    315\u001B[0m \u001B[38;5;124;03m    Can be overriden for batch queries.\u001B[39;00m\n\u001B[1;32m    316\u001B[0m \n\u001B[1;32m    317\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 318\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_embeddings\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_text_engine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdeployment_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeployment_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopenai_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:379\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    377\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 379\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    381\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:326\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    324\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreraise:\n\u001B[1;32m    325\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m retry_exc\u001B[38;5;241m.\u001B[39mreraise()\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfut\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexception\u001B[39;00m()\n\u001B[1;32m    328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwait:\n\u001B[1;32m    329\u001B[0m     sleep \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwait(retry_state)\n",
      "\u001B[0;31mRetryError\u001B[0m: RetryError[<Future at 0x7f8cea057bb0 state=finished raised APIRemovedInV1>]"
     ]
    }
   ],
   "source": [
    "vector_index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    service_context=service_context\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
